#!/usr/bin/env python3
"""
Test CFR Document Analyzer with mock LLM responses to demonstrate full functionality.
"""

import sys
import logging
from pathlib import Path

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

from cfr_document_analyzer.config import Config
from cfr_document_analyzer.database import Database
from cfr_document_analyzer.analysis_engine import AnalysisEngine
from cfr_document_analyzer.export_manager import ExportManager
from cfr_document_analyzer.models import SessionStatus, DOGEAnalysis, RegulationCategory


# Mock the LLM client to return sample responses
class MockLLMClient:
    """Mock LLM client that returns realistic DOGE analysis responses."""
    
    def __init__(self):
        from cfr_document_analyzer.llm_client import LLMUsageStats
        self.usage_stats = LLMUsageStats()
        self.usage_stats.total_calls = 1
        self.usage_stats.successful_calls = 1
        self.usage_stats.total_tokens = 1500
        self.usage_stats.total_time = 2.5
    
    def analyze_document_with_doge_prompts(self, content: str, document_id: str = None) -> DOGEAnalysis:
        """Return a realistic mock DOGE analysis."""
        
        # Simulate different responses based on document content
        if "information collection" in content.lower():
            return DOGEAnalysis(
                category=RegulationCategory.NOT_STATUTORILY_REQUIRED,
                statutory_references=[
                    "44 U.S.C. Â§ 3501 et seq. (Paperwork Reduction Act)",
                    "12 U.S.C. Â§ 1751 et seq. (Federal Credit Union Act)"
                ],
                reform_recommendations=[
                    "Simplify information collection requirements to reduce administrative burden on credit unions",
                    "Harmonize reporting requirements with other financial regulators",
                    "Implement electronic filing systems to modernize the process"
                ],
                justification="""This regulation appears to be Not Statutorily Required (NSR) as it implements 
administrative procedures for information collection that, while authorized by the Paperwork Reduction Act 
and Federal Credit Union Act, are not specifically mandated by statute. The regulation establishes 
procedures for collecting information from credit unions regarding their operations and compliance.

The statutory authority exists under 44 U.S.C. Â§ 3501 et seq. and 12 U.S.C. Â§ 1751 et seq., but the 
specific collection methods and requirements are agency-determined rather than congressionally mandated. 
This provides opportunity for streamlining and modernization without compromising regulatory oversight.

Reform recommendations focus on reducing compliance burden while maintaining necessary oversight, 
particularly through electronic systems and harmonization with other regulators' requirements."""
            )
        else:
            return DOGEAnalysis(
                category=RegulationCategory.STATUTORILY_REQUIRED,
                statutory_references=[
                    "12 U.S.C. Â§ 1751 (Federal Credit Union Act - General provisions)",
                    "12 U.S.C. Â§ 1766 (Examination and supervision)"
                ],
                reform_recommendations=[
                    "Modernize examination procedures to incorporate digital processes",
                    "Clarify regulatory language to reduce ambiguity"
                ],
                justification="""This regulation appears to be Statutorily Required (SR) as it directly implements 
specific congressional mandates under the Federal Credit Union Act regarding examination and supervision 
of federal credit unions."""
            )
    
    def get_usage_stats(self):
        return self.usage_stats


def test_with_mock_llm():
    """Test complete system with mock LLM responses."""
    # Set up logging
    Config.setup_logging(verbose=True)
    logger = logging.getLogger(__name__)
    
    logger.info("Testing CFR Document Analyzer with mock LLM responses...")
    
    try:
        # Initialize components
        db = Database(Config.DATABASE_PATH)
        engine = AnalysisEngine(db)
        
        # Replace the LLM client with our mock
        engine.llm_client = MockLLMClient()
        
        export_manager = ExportManager()
        
        logger.info("âœ“ Components initialized with mock LLM")
        
        # Test with NCUA
        agency_slug = "national-credit-union-administration"
        logger.info(f"Testing analysis with {agency_slug}")
        
        # Run analysis
        session = engine.analyze_agency_documents(
            agency_slug=agency_slug,
            prompt_strategy="DOGE Criteria",
            document_limit=1
        )
        
        logger.info(f"Analysis session: {session.session_id}")
        logger.info(f"Status: {session.status}")
        logger.info(f"Documents processed: {session.documents_processed}/{session.total_documents}")
        
        # Get results
        results = engine.get_analysis_results(session.session_id)
        logger.info(f"Retrieved {len(results)} analysis results")
        
        if results:
            result = results[0]
            analysis = result['analysis']
            
            logger.info("âœ“ MOCK ANALYSIS RESULTS:")
            logger.info(f"  Document: {result['document_number']}")
            logger.info(f"  Title: {result['title'][:100]}...")
            logger.info(f"  Category: {analysis['category']}")
            logger.info(f"  Statutory References: {len(analysis['statutory_references'])}")
            logger.info(f"  Reform Recommendations: {len(analysis['reform_recommendations'])}")
            logger.info(f"  Success: {analysis['success']}")
            
            # Show some content
            if analysis['statutory_references']:
                logger.info("  Sample Statutory Reference:")
                logger.info(f"    - {analysis['statutory_references'][0]}")
            
            if analysis['reform_recommendations']:
                logger.info("  Sample Reform Recommendation:")
                logger.info(f"    - {analysis['reform_recommendations'][0]}")
            
            if analysis['justification']:
                logger.info(f"  Justification Preview: {analysis['justification'][:200]}...")
            
            # Test export functionality
            logger.info("Testing export functionality...")
            exported_files = export_manager.export_session_results(
                results, session.session_id, ['json', 'csv', 'html']
            )
            
            summary_file = export_manager.create_agency_presentation_summary(
                results, session.session_id
            )
            
            logger.info("âœ“ EXPORT FILES GENERATED:")
            for format_name, filepath in exported_files.items():
                logger.info(f"  {format_name.upper()}: {filepath}")
            if summary_file:
                logger.info(f"  Agency Summary: {summary_file}")
        
        # Get usage statistics
        stats = engine.get_usage_statistics()
        logger.info("âœ“ USAGE STATISTICS:")
        logger.info(f"  Total calls: {stats['total_calls']}")
        logger.info(f"  Successful calls: {stats['successful_calls']}")
        logger.info(f"  Success rate: {stats['success_rate']:.1f}%")
        logger.info(f"  Total tokens: {stats['total_tokens']}")
        logger.info(f"  Total time: {stats['total_time']:.1f}s")
        
        engine.close()
        
        logger.info("\nðŸŽ‰ MOCK TEST SUCCESSFUL!")
        logger.info("The system demonstrates complete functionality:")
        logger.info("  âœ“ Document retrieval from Federal Register")
        logger.info("  âœ“ DOGE analysis with SR/NSR/NRAN categorization")
        logger.info("  âœ“ Statutory reference identification")
        logger.info("  âœ“ Reform recommendation generation")
        logger.info("  âœ“ Professional report generation")
        logger.info("  âœ“ Multiple export formats")
        logger.info("  âœ“ Agency presentation materials")
        
        logger.info("\nOnce the LLM integration is fixed, this will work with real AI analysis!")
        
        return True
        
    except Exception as e:
        logger.error(f"Mock test failed: {e}")
        return False


if __name__ == "__main__":
    success = test_with_mock_llm()
    print(f"\nTest result: {'SUCCESS' if success else 'FAILED'}")
    sys.exit(0 if success else 1)